# Debugging GemFire Applications (Work in Progress, please ignore me)

This article provides some practical suggestions for debugging GemFire Applications.

## GemFire Artifacts
* clusterConfig and cache.xml - provided by the application developer to configure the caches and regions for GemFire client and server processes.
* properties files - provided by the application developer to configure system properties and membership discovery
* System logs - logs generated by GemFire clients, servers, and locators. The contain information about membership, client connections, warnings about outstanding message requests and errors.  The log also displays the system properties.
* Statistics - archive files generated by GemFire clients and/or servers containing information about the GemFire application. GemFire VSD (Visual Statistics Display) is used to graph the GemFire and system metrics recorded in these archives. 

## Gathering additional information
### gfsh
GemFire gfsh provides a command-line interface from which you can launch, manage, and monitor GemFire processes, data, and applications.  The shell provides commands useful in debugging (to bring all the information to one location) such as:
* export logs
* export stack-traces
* show log
* show dead-locks
_Note that the commands above require executing the gfsh ```connect``` command to establish the connection to the locator or JMX Manager of the distributed system._

### Stack dumps
When debugging, it is best to get stack dumps for all VMs.  To determine if progress is being made, execute multiple thread dumps several seconds apart for comparison.  The following command prints the stacks for all threads in the given pid to STDOUT (so these should be redirected to files named for each specific vm or pid).
``` 
$ kill -3 <pid>
```
### Memory Analyzers
* [jhat](http://docs.oracle.com/javase/7/docs/technotes/tools/share/jhat.html)
* [Eclipse Memory Analyzer](https://eclipse.org/mat/)

## General Guidelines
1. Check your environment - Machine (O/S and System settings), JDK, JVM properties (-Xmx -Xms), GC parameters
1. Draw out a diagram of your system topology (servers, clients) and make a note of Listeners, Writers and other plug-ins.  
1. Verify your cache and region configuration
1. Confirm your system properties (Review properties files and display in system log)
1. On your system topology diagram, add notes on the initialization and other processing being done in different classes of members.  If you are debugging a specific interaction between systems, draw a sequence diagram.

## Scan the system logs for suspect strings that can guide you to specific vms and potential problems
1. If possible, bring all the system logs and stack dumps together into a single directory for inspection (use gfsh commands above).
1. Search the system logs for warning, error or severe messages
1. Search the system logs for any underlying Exceptions (perhaps thrown from user supplied plug-ins).  For example: ConcurrentModificationException, NullPointerException, SerializationException.
1. Search the system logs for warnings about resources causing delays in statistics sampling.  If found, use VSD to investigate further.
```
[warning 2015/03/29 04:47:23.028 PDT gemfire1_w1-gst-dev26_15651 <Thread-5 StatSampler> tid=0x55] Statistics sampling thread detected a wakeup delay of 8,310 ms, indicating a possible resource issue. Check the GC, memory, and CPU statistics.
```
1. Verify there are no hotspot (hs_err*.log files) indicating a HotSpot error in the JVM
These are readable files that provide details about the HotSpot Error.
1. Verify that there are no heapdump (*.hprof) files or OutOfMemoryErrors.
Tools such as jhat and Eclipse MemoryAnalyzer can provide heap histograms and leak suspects.
1. Search the stack dumps for "Java-level deadlock".  Dumping the stacks using jstack or ```kill -3 <pid>``` will also show you any Java-level deadlocks including the threads involved in the deadlock as well as the stack dumps for each of those threads.
1. Search the system logs for any "15 seconds have elapsed messages" which don't have corresponding "wait for replies has completed" logs.  You can match these log messages together via the thread id or native thread id.
In this example, we can see that the request did complete, so while we should be concerned (and possibly check stats in vsd to see what system resources are causing this delay), it will not be the cause of our hang.
```
TBD
```
If the request is never satisfied (there is no corresponding 'wait for replies completed' message') as in the example below, look at the stack dumps for the non-responsive member.  There could be a Java-level deadlock within that vm.
```
TBD 
```
There can also be distributed deadlocks between members.  This requires following the "15 seconds have elapsed" warnings to the remote vms and looking at the stack dumps.  Searching for "waiting to lock" in the stack dumps can also lead you to the culprit
```
TBD
```

## Clients fail with ServerConnectivityExceptions
This can occur if servers are too busy to process client requests (for example with GC or distributed deadlocks).
* client connections expiration/timeout
* readTimeouts
```
TBD
```

## Tips for improving ability to debug during development

### pass in the vm and thread id as arguments (to be logged) during Function Execution
```
Example TBD
```
### Use of CacheListeners to log events as they are processed
```
Example TBD
```
### Use of CacheListeners in clients to trace server side processing
```
Example TBD
```